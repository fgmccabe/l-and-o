test.modsec{
  -- Test of L&O by parsing modsecurity rules.

  import lo.
  import lo.uri.
  import lo.resources.
  import lo.json.

  type modSecRule ::= modSecRule(list[string],string,list[msAct]) | modSecMarker(string).

  type msTgt ::= headers | header(string) | args | arg(string) | local(string) | pattern(string).

  type msAct ::= single(string) | id(string) | tag(string) | other(string,string).

  -- Hint to the run-time:
  main:(list[string]){}.
  main(Args) :-
    processFiles(parseArgs(Args),cwd(),meta([],[]),M),
    _logmsg("Analysis is \(M::json)").

  parseArgs:(list[string]) => list[uri].
  parseArgs([]) => [].
  parseArgs([f,..l]) => [parseUri(f),..parseArgs(l)].

  processFiles:(list[uri],uri,meta,meta){}.
  processFiles([],_,M,M).
  processFiles([u,..l],c,M,Mx) :-
    procFile(resolveUri(c,u),L,M,M0),
    processFiles(l,c,M0,Mx).

  procFile:(uri,list[modSecRule],meta,meta){}.
  procFile(U,Rls,M,Mx) :-
    (lines(Lns) %% getResource(U))!,
    -- _logmsg("Lines are \(Lns::list[string])"),
    Tks = tokenize(Lns),
    _logmsg("Tokens are \(Tks)"),
    Rls = secRules(Tks),
    _logmsg("Rules are \(Rls::list[json])"),
    analyseRules(Rls,M,Mx).

  private analyseRules:(list[modSecRule],meta,meta){}.
  analyseRules([],M,M).
  analyseRules([Rl,..l],M,Mx) :-
    analyseRules(l,M.addRule(Rl),Mx).

  type meta <~ {tgts:map[string,list[string]]. tags:map[string,list[string]]. addRule:(modSecRule) => meta.}.

  private meta:(map[string,list[string]],map[string,list[string]]) <=> meta.
  meta(Tgts,Tags) {
    tgts = Tgts.
    tags = Tags.
    addRule(Rl) => meta(merge(Tgts,M.target,M.id),merge(Tags,M.tags,M.id)) :- extractMetaFromRule(Rl,M).
    addRule(_) => this.

    private merge:(map[string,list[string]],list[string],string) => map[string,list[string]].
    merge(M,[],_) => M.
    merge(M,[e,..l],i) => merge(M[e->[i,..ids]],l,i) :- present(M,e,ids).
    merge(M,[e,..l],i) => merge(M[e->[i]],l,i).
  }

  implementation coercion[meta,json] .. {
    _coerce(M) => meta2json(M).
  }

  private meta2json:(meta)=>json.
  meta2json(meta(Tgts,Tags)) => jColl(["targets" -> jColl(tags2json(Tgts)), "tags"->jColl(tags2json(Tags))]).

  tags2json:(map[string,list[string]]) => map[string,json].
  tags2json(M) => mapMap(M,lst).

  lst:{ apply:(list[string]) => json }.
  lst{ 
    apply(L) => jSeq(listify(L)).

    private listify:(list[string]) => list[json].
    listify([])=>[].
    listify([s,..l]) => [jTxt(s),..listify(l)].
  }

  extractMetaFromRule:(modSecRule,{id:string. target:list[string]. tags:list[string]}){}.
  extractMetaFromRule(modSecRule(Tgt,Pth,Acts),metaAnal(Id,Tgt,findTags(Acts,[]))) :-
    id(Id) in Acts.

  private metaAnal:(string,list[string],list[string]) <=> {id:string. target:list[string]. tags:list[string]}.
  metaAnal(Id,Tgt,Tags){
    id = Id.
    target = Tgt.
    tags = Tags.
  }

  findTags:(list[msAct],list[string]) => list[string].
  findTags([],Tgs) => Tgs.
  findTags([tag(T),..l],Tgs) => findTags(l,[T,..Tgs]).
  findTags([_,..l],Tgs) => findTags(l,Tgs).

  implementation display[modSecRule] .. {
    disp(modSecRule(Tgt,Ptn,A)) => ssSeq([ss("SecRule:"),dispTgt(Tgt),ss(" "),ss(Ptn),ss("-->"),dispActions(A)]).
    disp(modSecMarker(Id)) => ssSeq([ss("SecMarker:"),ss(Id)]).
  }

  implementation display[msAct] .. {
    disp(single(S)) => ss(S).
    disp(id(S)) => ssSeq([ss("id:'"),ss(S),sc(0c')]).
    disp(tag(S)) => ssSeq([ss("tag:'"),ss(S),sc(0c')]).
    disp(other(V,A)) => ssSeq([ss(V),ss(":'"),ss(A),ss("'")]).
  }

  private dispTgt:(list[string]) => ss.
  dispTgt(T) => disp(T).

  private dispActions:(list[msAct]) => ss.
  dispActions(A) => disp(A).

  implementation coercion[modSecRule,json] .. {
    _coerce(modSecRule(Tgt,Ptn,[])) =>  jColl(["SecRule" -> jColl(["target" -> jSeq(jStrings(Tgt)), "pattern"->jTxt(Ptn)])]).
    _coerce(modSecRule(Tgt,Ptn,Action)) => jColl(["SecRule" -> jColl(["target" -> jSeq(jStrings(Tgt)), "pattern"->jTxt(Ptn), "action"->jSeq(jActions(Action))])]).
    _coerce(modSecMarker(Id)) => jColl(["SecMarker" -> jTxt(Id)]).
  }

  jActions:(list[msAct]) => list[json].
  jActions([]) => [].
  jActions([S,..L]) => [S::json,..jActions(L)].

  implementation coercion[msAct,json] .. {
    _coerce(single(A)) => jColl(["verb"->jTxt(A)]).
    _coerce(id(I)) => jColl(["id" -> jTxt(I)]).
    _coerce(tag(T)) => jColl(["tag"->jTxt(T)]).
    _coerce(other(V,A)) => jColl(["verb"->jTxt(V), "arg"->jTxt(A)]).
  }

  jStrings:(list[string]) => list[json].
  jStrings([]) => [].
  jStrings([S,..L]) => [jTxt(S),..jStrings(L)].

  secRules:(list[list[secTkn]]) => list[modSecRule].
  secRules([]) => [].
  secRules([Ln,..L]) => [Rl,..secRules(L)] :- rule(Rl) %% Ln.

  -- Parse a line as a mod security rule
  rule:(modSecRule) --> list[secTkn].
  rule(modSecRule(Tgt,Ptn,Action)) --> [secRule], target(Tgt), pattern(Ptn), actions(Action).
  rule(modSecMarker(implode(Id))) --> [secMarker], [idn(Id)].

  target:(list[string]) --> list[secTkn].
  target(T) --> [idn(S)], { tgtSeq(T) %% S}.

  tgtSeq:(list[string]) --> list[integer].
  tgtSeq([]) --> eof.
  tgtSeq([implode(I),..L]) --> frag(I,[],0c|), moreTgts(L).

  moreTgts:(list[string]) --> list[integer].
  moreTgts([]) --> eof.
  moreTgts(L) --> "|", tgtSeq(L).

  pattern:(string) --> list[secTkn].
  pattern(P) --> [strg(S)], {P = implode(S)}.

  actions:(list[msAct]) --> list[secTkn].
  actions(A) --> [strg(S)], { (spaces(), actionSeq(A)) %% S}.
  actions([A]) --> [idn(S)], {action(A) %% S}.
  actions([]) --> eof.

  actionSeq:(list[msAct]) --> list[integer].
  actionSeq([]) --> eof.
  actionSeq([I,..L]) --> action(I), spaces(), moreActions(L).

  moreActions:(list[msAct]) --> list[integer].
  moreActions([]) --> eof.
  moreActions(L) --> ",", spaces(), actionSeq(L).

  action:(msAct) --> list[integer].
  action(id(I)) --> "id:", spaces(), arg(I).
  action(tag(T)) --> "tag:", spaces(), arg(T).
  action(other(implode(V),A)) --> iden(V), spaces(), ":", spaces(), arg(A).
  action(single(implode(A))) --> iden(A).

  arg:(string) --> list[integer].
  arg(implode(A)) --> "'", frag(A,[],0c')!, "'".
  arg(implode(A)) --> frag(A,[],0c,).

  iden:(list[integer]) --> list[integer].
  iden([C,..L]) --> idStart(C), moreIden(L).

  idStart:(integer) --> list[integer].
  idStart(0c_) --> [0c_].
  idStart(Ch) --> [Ch] , {_isLetterChar(Ch)}.

  moreIden:(list[integer]) --> list[integer].
  moreIden([C,..L]) --> alphaNum(C), moreIden(L).
  moreIden([]) --> [].

  alphaNum:(integer) --> list[integer].
  alphaNum(Ch) --> idStart(Ch).
  alphaNum(Ch) --> [Ch] , {_isNdChar(Ch) }!.

  -- Absorb the \eol markers into a sequence of lines.

  lines:(list[list[integer]]) --> list[integer].
  lines([]) --> eof.
  lines(Lns) --> line(Ln)!, {glue(Lns,Ln,Rest)}, lines(Rest).

  line:(list[integer]) --> list[integer].
  line([]) --> "\n".
  line(Ln) --> "\\\n", line(Ln).
  line([C,..L]) --> [C],line(L).
  line([]) --> eof.

  private glue:(list[list[integer]],list[integer],list[list[integer]]){}.
  glue(Text,Ln,Text) :- blankLine(Ln)!.
  glue([Ln,..Rest],Ln,Rest) :- \+blankLine(Ln).

  private blankLine:(list[integer]){}.
  blankLine([]).
  blankLine(L) :- spaces() %% L.

  -- Tokenization of modsecurity source

  private type secTkn ::= secRule | secAction | secDefaultAction | secMarker | secRuleUpdate
   | idn(list[integer]) | strg(list[integer]).

  implementation display[secTkn] .. {
    disp(secAction) => ss("SecAction").
    disp(secRule) => ss("SecRule").
    disp(secMarker) => ss("SecMarker").
    disp(secDefaultAction) => ss("SecDefaultAction").
    disp(secRuleUpdate) => ss("SecRuleUpdate").
    disp(strg(Seq)) => ssSeq([ss("\""), ss(implode(Seq)), ss("\"")]).
    disp(idn(Text)) => ssSeq([ss("'"), ss(implode(Text)), ss("'")]).
  }

  tokenize:(list[list[integer]]) => list[list[secTkn]].
  tokenize([]) => [].
  tokenize([l,..ll]) => [tks,..tokenize(ll)] :- tokens(tks) %% l.

  tokens:(list[secTkn]) --> list[integer].
  tokens(Toks) --> spaces(), moreToks(Toks).

  spaces:()-->list[integer].
  spaces() --> space(), spaces().
  spaces() --> \+ space().

  space:()-->list[integer].
  space() --> ([0c ] | [0c\t])!.
  space() --> "#", eol().

  eol:()-->list[integer].
  eol() --> "\n".
  eol() --> [C], { C \= 0c\n}, eol().
  eol() --> eof.

  moreToks:(list[secTkn]) --> list[integer].
  moreToks([]) --> eof.
  moreToks([Tok,..More]) --> token(Tok), tokens(More).

  token:(secTkn) --> list[integer].
  token(secRule) --> ("SecRule"|"secrule"|"Secrule"|"SECRULE")!.
  token(secAction) --> ("SecAction"|"Secaction"|"secaction"|"SECACTION")!.
  token(secMarker) --> ("SecMarker"|"Secmarker"|"secmarker"|"SECMARKER")!.
  token(strg(Seq)) --> "\"", stringText(Seq), "\"".
  token(idn(Text)) --> frag(Text,[],0c ).

  iden:(list[integer]) --> list[integer].
  iden(L) --> frag(L,[],0c ).

  frag:(list[integer],list[integer],integer) --> list[integer].
  frag(L,L,_) --> eof.
  frag(L,X,Dl) --> [0c\\,0c\\], frag(L,X,Dl).
  frag([0c\\,..L],X,Dl) --> [0c\\], frag(L,X,Dl).
  frag(L,L,Dl) --> [Dl]+.
  frag([C,..L],X,Dl) --> [C], frag(L,X,Dl).

  stringText:(list[integer]) --> list[integer].
  stringText([C,..More]) --> "\\", [C], stringText(More).
  stringText([C,..More]) --> [C], { C \= 0c" }, stringText(More).
  stringText([]) --> "\""+.
}